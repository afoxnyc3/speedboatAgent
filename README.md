# RAG Agent - AI-Powered Knowledge Assistant

An intelligent knowledge assistant that provides instant, accurate answers from GitHub repositories and web documentation through hybrid search, with zero hallucination tolerance.

## ðŸŽ¯ Mission

Save 40 engineering hours by building a production-ready RAG agent that unifies code understanding and documentation retrieval across GitHub repositories and web sources.

## âš¡ Core Features

### Intelligent Capabilities
- **Natural Language Q&A** - Query your entire codebase conversationally
- **Hybrid Data Sources** - Unified search across GitHub repos and web documentation
- **Stealth Mode** - Local repository ingestion with zero production impact
- **Real-time Sync** - GitHub webhooks for instant updates (optional)
- **Source Attribution** - Every answer includes clickable source links
- **Conversation Memory** - Understands context from previous questions
- **Zero Hallucination** - If we don't know, we say so

### Performance Guarantees
- Response time: < 2s (p95)
- First token: < 100ms
- Cache hit rate: > 70%
- Query coverage: 95%
- Update lag: < 30s for GitHub, < 1 week for web

## ðŸ› ï¸ Technology Stack

### Core Infrastructure
- **Framework**: Next.js 14 (App Router) + TypeScript
- **Vector DB**: Weaviate Cloud (Hybrid Search)
- **LLM**: OpenAI GPT-4 Turbo
- **Embeddings**: text-embedding-3-large (1024 dims)

### Processing & Intelligence
- **GitHub Processing**: LlamaIndex (AST-aware parsing)
- **Web Crawling**: Firecrawl (selective scraping)
- **Memory System**: Mem0 (conversation context)
- **Reranking**: cross-encoder-ms-marco-MiniLM-L-6-v2
- **Queue**: BullMQ (async job processing)
- **Cache**: Upstash Redis (embedding cache)

### Monitoring & Operations
- **Error Tracking**: Sentry
- **Analytics**: Vercel Analytics
- **Rate Limiting**: 100 req/min per IP
- **Deployment**: Vercel

## ðŸ“¦ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/afoxnyc3/speedboatAgent.git
cd speedboatAgent

# Install dependencies
npm install

# Set up environment variables
# Create .env.local with your API keys

# Test connections
npm run test-weaviate

# Initialize Weaviate schema
npm run setup-weaviate development

# Local ingestion (stealth mode)
npm run ingest-local /path/to/your/repo --dry-run
npm run ingest-local /path/to/your/repo

# Run development server
npm run dev
```

### Environment Configuration

```env
# Core Services (Required for Week 1)
OPENAI_API_KEY=sk-...
WEAVIATE_HOST=https://your-cluster.weaviate.cloud
WEAVIATE_API_KEY=...

# Local Ingestion Mode (Stealth)
LOCAL_REPO_PATH=/path/to/your/repository

# Optional for Week 1
GITHUB_TOKEN=ghp_...
# GITHUB_WEBHOOK_SECRET not needed for local mode

# Infrastructure (Week 2+)
UPSTASH_REDIS_URL=...
UPSTASH_REDIS_TOKEN=...

# Enhanced Features (Week 3-4)
MEM0_API_KEY=...
FIRECRAWL_API_KEY=...

# Monitoring (Production)
SENTRY_DSN=...
VERCEL_ENV=...
```

## ðŸ“ Project Structure
```
/src
  /app
    /api
      /chat/route.ts          # Streaming chat endpoint
      /ingest
        /github/route.ts      # GitHub webhook receiver
        /web/route.ts         # Web crawl trigger
      /search/route.ts        # Direct search API
      /feedback/route.ts      # User feedback collection
      /health/route.ts        # System status
  /lib
    /ingestion
      /github-processor.ts    # LlamaIndex GitHub ingestion
      /web-crawler.ts        # Firecrawl web ingestion
      /deduplication.ts      # Content deduplication
    /search
      /hybrid-search.ts      # Weaviate queries
      /query-classifier.ts   # Query type detection
      /reranker.ts          # Result reranking
    /cache
      /embedding-cache.ts    # Redis caching
    /memory
      /mem0-client.ts       # Conversation memory
    /weaviate
      /client.ts            # Connection management
      /schema.ts            # Schema definition
  /components
    /chat
      /ChatInterface.tsx    # Main UI component
      /SourceViewer.tsx     # Citation display
      /FeedbackWidget.tsx   # User feedback
```

## ðŸš€ Implementation Timeline

### Week 1: Foundation âœ… COMPLETE
- âœ… Weaviate schema with hybrid search (11 properties)
- âœ… Local ingestion pipeline via LlamaIndex (477 files processed)
- âœ… Stealth operation mode (zero production impact)
- âœ… Document processing with rich metadata
- âœ… OpenAI embeddings integration (text-embedding-3-large)

### Week 2: Intelligence ðŸš§
- Query classification system
- Source authority weighting
- Streaming responses with GPT-4
- Source attribution

### Week 3: Hybrid Data ðŸ“…
- Firecrawl web ingestion
- Deduplication pipeline
- Source routing optimization

### Week 4: Production ðŸ“…
- Mem0 conversation memory
- Feedback system
- Performance optimization
- Monitoring setup

## ðŸ“Š Data Sources & Priorities

### GitHub Sources (Priority: 1.2x)
```yaml
File Types:
  - .ts, .tsx (TypeScript)
  - .md, .mdx (Documentation)
  - .json, .yaml (Configuration)

Processing:
  - AST parsing for code understanding
  - Preserves function context
  - Extracts comments and docstrings
  - Real-time updates via webhooks
```

### Web Sources (Priority: 0.8x)
```yaml
Targets:
  - docs.company.com
  - api.company.com
  - help.company.com

Exclusions:
  - /blog/*
  - /careers/*
  - /legal/*

Schedule:
  - Weekly full crawl
  - Daily incremental updates
  - Change detection enabled
```

### Query Routing Logic
```typescript
const queryWeights = {
  'technical': {
    github: 1.5,  // Prefer code for technical questions
    web: 0.5
  },
  'business': {
    github: 0.5,
    web: 1.5      // Prefer docs for business questions
  },
  'operational': {
    github: 1.0,  // Balanced for operational queries
    web: 1.0
  }
}
```

## ðŸ“ˆ Success Metrics

### Technical Metrics
- âœ… 95% query coverage from hybrid sources
- âœ… < 100ms p50 vector search latency
- âœ… 0% hallucination rate
- âœ… 70%+ cache hit rate

### Business Metrics
- âœ… 40 engineering hours saved
- âœ… 50% reduction in discovery time
- âœ… 85%+ user satisfaction
- âœ… ROI positive within 60 days

## ðŸ”’ Security & Reliability

### Security Measures
- GitHub webhook signature verification (HMAC)
- API key rotation via Vercel KV
- Rate limiting (100 req/min per IP)
- Input sanitization with Zod schemas
- No credentials in code

### Reliability Features
- BullMQ for reliable job processing
- Retry logic with exponential backoff
- Dead letter queue for failed jobs
- Health checks and monitoring
- Graceful degradation

## ðŸš¢ Deployment

### Production Checklist
```bash
# Pre-deployment
â–¡ Weaviate schema configured
â–¡ Initial content indexed
â–¡ Cache warmed up
â–¡ Environment variables set
â–¡ Rate limiting enabled

# Deployment
npm run build
npm run test:prod
vercel --prod

# Post-deployment
â–¡ Monitor error rates
â–¡ Check response times
â–¡ Verify cache hit rates
â–¡ Test webhook delivery
```

## ðŸ“š Documentation

- [CLAUDE.md](./CLAUDE.md) - Technical implementation details
- [project-spec.md](./project-spec.md) - Full specification
- [roadmap.md](./roadmap.md) - Development timeline
- [todo.md](./todo.md) - Current sprint tasks

## ðŸ¤ Contributing

1. Check GitHub issues for current tasks
2. Create feature branch: `feature/<issue-id>-<description>`
3. Follow code standards (15-line functions, 100-line files)
4. Ensure tests pass
5. Create pull request

## ðŸ“„ License

MIT

---

Built for production-ready knowledge retrieval at scale with zero hallucinations